{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u':', u'capital-common-countries'], [u'Athens', u'Greece', u'Baghdad', u'Iraq'], [u'Athens', u'Greece', u'Bangkok', u'Thailand']]\n"
     ]
    }
   ],
   "source": [
    "# import modules & set up logging\n",
    "import gensim, logging\n",
    "from gensim.models import Word2Vec\n",
    "import io\n",
    "\n",
    "sentences = io.open(\"/home/dong/questions-words.txt\", \"r\")\n",
    "sentences = [x.strip() for x in sentences]\n",
    "data = list()\n",
    "for s in sentences:\n",
    "    data.append(s.split())\n",
    "print data[0:3]\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "\n",
    "# train word2vec on the two sentences\n",
    "# model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-08 10:16:54,612 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2017-12-08 10:16:54,613 : INFO : collecting all words and their counts\n",
      "2017-12-08 10:16:54,615 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-12-08 10:16:54,616 : INFO : collected 8 word types from a corpus of 15 raw words and 3 sentences\n",
      "2017-12-08 10:16:54,618 : INFO : Loading a fresh vocabulary\n",
      "2017-12-08 10:16:54,619 : INFO : min_count=1 retains 8 unique words (100% of original 8, drops 0)\n",
      "2017-12-08 10:16:54,620 : INFO : min_count=1 leaves 15 word corpus (100% of original 15, drops 0)\n",
      "2017-12-08 10:16:54,621 : INFO : deleting the raw counts dictionary of 8 items\n",
      "2017-12-08 10:16:54,623 : INFO : sample=0.001 downsamples 8 most-common words\n",
      "2017-12-08 10:16:54,624 : INFO : downsampling leaves estimated 1 word corpus (9.4% of prior 15)\n",
      "2017-12-08 10:16:54,625 : INFO : estimated required memory for 8 words and 10 dimensions: 4640 bytes\n",
      "2017-12-08 10:16:54,627 : INFO : resetting layer weights\n",
      "2017-12-08 10:16:54,628 : INFO : training model with 3 workers on 8 vocabulary and 10 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-12-08 10:16:54,631 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-12-08 10:16:54,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-12-08 10:16:54,634 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-12-08 10:16:54,636 : INFO : training on 75 raw words (9 effective words) took 0.0s, 1674 effective words/s\n",
      "2017-12-08 10:16:54,637 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences, size = 10, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.15877169658938864"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('tree', 'cat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
